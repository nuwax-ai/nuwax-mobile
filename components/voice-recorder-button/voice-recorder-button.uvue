<template>
  <button class="voice-recorder-container" 
    hover-class="hover-class"
    hover-start-time="10"
    @touchstart="handleTouchStart"
    @touchend="handleTouchEnd"
    @touchcancel="cancelRecording">
    <!-- 波形动画 -->
    <view v-if="currentState === 'recording'" class="waveform">
      <view 
        v-for="(bar, index) in waveformBars"
        :key="index"
        class="waveform-bar"
        :style="{ height: `${bar.height}px`, animationDelay: `${bar.delay}ms` }"
      />
    </view>
    <!-- 状态提示文字 -->
    <text v-else>{{ currentState === 'default' ? '按住说话' : currentState === 'uploading' ? '语音识别中' : '' }}</text>
  </button>
</template>

<script lang="uts" setup>
import jzRecorder from '@/uni_modules/jz-h5-recorder-manager'
import { 
  createAudioUploader, 
  type AudioFile as UploaderAudioFile,
  type TranscriptResult as UploaderTranscriptResult,
  type UploadProgress
} from '@/servers/audioUploader'
import { MicrophonePermissionHelper, type PermissionState } from '@/utils/permissionHelper'

// 组件Props类型定义
interface VoiceRecorderProps {
  // 录音配置
  duration?: number        // 最大录音时长 (ms)
  format?: string         // 音频格式
  sampleRate?: number     // 采样率
  // 会话是否正在进行中（有消息正在处理）
  isConversationActive?: boolean
}

// 录音状态类型
type RecordState = 'default' | 'recording' | 'uploading' | 'success' | 'error'

// 音频文件接口
interface AudioFile {
  tempFilePath: string
  duration: number
  fileSize: number
  format?: string
}

// 转换结果接口
interface TranscriptResult {
  success: boolean
  text: string
  confidence: number
  duration: number
  error?: string
}

const props = withDefaults(defineProps<VoiceRecorderProps>(), {
  duration: 60000,
  format: 'mp3',
  sampleRate: 44100,
  isConversationActive: false
})

const emit = defineEmits<{
  // 事件回调
  onRecordStart?: () => void,
  onRecordStop?: (result: string) => void,
  onError?: (error: any) => void,
  onUploadProgress?: (progress: number) => void
  onCancelChange?: (isCancelled: boolean) => void
  onRecordCancel?: () => void
  onRecordEnd?: () => void 
}>()

// 响应式状态
const currentState = ref<RecordState>('default')
const isCancelled = ref<boolean>(false)
// 波形动画数据
const waveformBars = ref([])
// 会话是否正在进行中
const isConversationActive = computed(() => props.isConversationActive)
// const buttonRect = reactive({
//   left: 0,
//   top: 0,
//   width: 0,
//   height: 0,
//   right: 0,
//   bottom: 0
// })

// 录音管理器
let recorderManager: any = null
let durationTimer: any = null

// 音频上传服务
let audioUploadService: any = null // 使用audioUploader


// Add watch for isCancelled to emit changes
// watch(isCancelled, (newVal) => {
//   emit('onCancelChange', newVal)
// })

// 初始化波形动画数据
const initWaveform = () => {
  // Dynamically generate waveform bars based on 80% of width
  const targetWidth = 640 * 0.8 // rpx
  const barWidth = 6 // rpx
  const gap = 4 // rpx
  const numBars = Math.max(3, Math.floor((targetWidth + gap) / (barWidth + gap))) // At least 3 bars
  
  waveformBars.value = Array.from({ length: numBars }, (_, index) => ({
    height: Math.random() * 20 + 5, // Initial random height 5-25
    delay: index * 100
  }))
}

// 初始化录音管理器
onMounted(() => {
  recorderManager = jzRecorder.getRecorderManager()
  // 设置录音事件监听
  setupRecorderEvents()
  
  // 初始化音频上传服务
  initializeAudioUploadService()
  // 初始化波形动画数据
  initWaveform()

  // nextTick(() => {
  //   const query = uni.createSelectorQuery().in(this as any)
  //   query.select('.voice-recorder-container').boundingClientRect((data: any) => {
  //     if (data) {
  //       buttonRect.left = data.left
  //       buttonRect.top = data.top
  //       buttonRect.width = data.width
  //       buttonRect.height = data.height
  //       buttonRect.right = data.right
  //       buttonRect.bottom = data.bottom
  //       // emit('onButtonRect', {...buttonRect})
  //     }
  //   }).exec()
  // })
})

// 初始化音频上传服务
const initializeAudioUploadService = () => {
  audioUploadService = createAudioUploader()
}

// 重置状态
const resetState = () => {
  currentState.value = 'default'
  isCancelled.value = false
}

// 录音错误
const handleRecordError = (err: any) => {
  stopDurationTimer()
  resetState()
  emit('onError', err)
}

// 设置录音事件监听
const setupRecorderEvents = async() => {
  if (!recorderManager) return
  // 录音错误
  recorderManager.onError(handleRecordError)
  // 录音停止
  recorderManager.onStop(handleRecordStop)
}

// 开始录音时长计时
const startDurationTimer = () => {
  durationTimer = setInterval(() => {
    updateWaveform()
  }, 100)
}

// 停止录音时长计时
const stopDurationTimer = () => {
  if (durationTimer) {
    clearInterval(durationTimer)
    durationTimer = null
  }
}

// 更新波形动画
const updateWaveform = () => {
  waveformBars.value = waveformBars.value.map(bar => ({
    ...bar,
    height: Math.random() * 20 + 5
  }))
}

// const CANCEL_THRESHOLD = 100 // px
// // 录音中移动
// const handleTouchMove = (e: any) => {
//   if (currentState.value !== 'recording' || !e.touches || e.touches.length === 0) return
  
//   const touch = e.touches[0]
//   const deltaY = buttonRect.top - touch.pageY
//   isCancelled.value = deltaY > CANCEL_THRESHOLD
// }

// 开始录音
const handleTouchStart = async (e) => {
  console.time('touchstart')
  e.preventDefault() // Prevent default to avoid context menu
  console.log('handleTouchStart11111', currentState.value, props.isConversationActive, isConversationActive.value)

  console.timeLog('touchstart')
  // uni.showToast({
  //   title: '当前录音状态为：' + currentState.value,
  //   icon: 'none'
  // })

  if (isConversationActive.value) {
    emit('onError', new Error('会话正在进行中，请先暂停现有会话'))
    return
  }
  if (currentState.value !== 'default') {
    // emit('onError', new Error('请先停止当前录音' + currentState.value))
    return
  }
  // 设置状态，开始录音，并触发事件
  currentState.value = 'recording'
  startDurationTimer()
  emit('onRecordStart')

  // // #ifdef WEB
  // // 确保麦克风权限可用
  // const hasPermission = await MicrophonePermissionHelper.ensure(true)
  // if (!hasPermission ) {
  //   return
  // }
  // // #endif

  console.timeEnd('touchstart')
  // 开始录音
  if (recorderManager) {
    console.log('开始录音-----：handleTouchStart11111')
    try {
      recorderManager.start({
        duration: props.duration,
        sampleRate: props.sampleRate,
        numberOfChannels: 1,
        encodeBitRate: 192000,
        format: props.format
      })
    } catch (error: any) {
      resetState()                                                                            
      emit('onError', error)
    }
  }
}

// 录音中结束
const handleTouchEnd = (e) => {
  console.time('touchend')
  e.preventDefault() // Prevent default
  console.log('录音中结束-----：handleTouchEnd222222', currentState.value, isCancelled.value)

  // 如果正在上传，则不停止录音
  if (currentState.value === 'uploading') {
    return
  }
  if (isCancelled.value) {
    cancelRecording()
  } else {
    stopRecording()
  }
  console.timeEnd('touchend')
}

// 取消录音
const cancelRecording = () => {
  if (recorderManager) {
    recorderManager.stop()
  }
  resetState()
  emit('onRecordCancel')
}

// 录音停止
const handleRecordStop = async (res: AudioFile) => {
  stopDurationTimer()
  console.log('handleRecordStop99999', res)
  // 检查录音时长（最短0.5秒），如果录音时间太短，直接取消
  if (res.duration < 0.5) {
    resetState()
    emit('onError', new Error('录音时长过短，至少需要0.5秒'))
    return
  }
  
  // 立即显示上传中状态，给用户明确反馈
  currentState.value = 'uploading'
  
  try {
    // 使用音频上传服务转换音频
    const result = await uploadAndConvertWithService(res)
    if (result.success) {
      currentState.value = 'success'
      emit('onRecordStop', result.text)
      // 重置状态
      resetState()
    } else {
      throw new Error(result?.text || '未识别到文字')
    }
  } catch (error: any) {
    handleRecordError(error)
  }
}

// 停止录音
const stopRecording = () => {
  if (recorderManager) {
    try {
      recorderManager.stop()
      emit('onRecordEnd')
    } catch (error: any) {
      currentState.value = 'error'
      emit('onError', error)
    }
  }
  // 重置状态
  resetState()
}

// 使用audioUploader转换音频
const uploadAndConvertWithService = async (audioFile: AudioFile): Promise<TranscriptResult> => {
  if (!audioUploadService) {
    throw new Error('音频上传服务未初始化')
  }

  try {
    // 转换音频文件格式
    const uploaderAudioFile: UploaderAudioFile = {
      tempFilePath: audioFile.tempFilePath,
      duration: audioFile.duration,
      fileSize: audioFile.fileSize,
      format: audioFile.format
    }

    // 调用audioUploader的上传方法
    const result = await audioUploadService.uploadAudio(uploaderAudioFile)

    // 转换结果格式
    return {
      success: result.success,
      text: result.text,
      // confidence: result.confidence,
      // duration: result.duration,
      // error: result.error
    }
  } catch (error: any) {
    return {
      success: false,
      text: error.message,
    }
  }
}

// 组件卸载时清理资源
onUnmounted(() => {
  stopDurationTimer()
  if (recorderManager) {
    // 清理事件监听器
    recorderManager.offStop(handleRecordStop)
  }
})
</script>

<style lang="scss" scoped>
  .voice-recorder-container {
    flex: 1;
    display: flex;
    flex-direction: row;
    align-items: center;
    justify-content: center;
    height: 112rpx;
    border-radius: 24rpx;
    transition: all 0.15s ease;
    -webkit-touch-callout: none;
    user-select: none;
    color: #000;
    font-size: 32rpx;
    font-weight: 400;
    background-color: transparent;
    padding: 0; // 删除uni-button默认padding

    &.hover-class {
      background-color: #5147FF;
      z-index: 100;

      text {
        color: #fff;
      }
    }

    .waveform {
      display: flex;
      flex-direction: row;
      align-items: center;
      justify-content: center;
      gap: 4rpx;
      z-index: 0;
      width: 100%;
      height: 100%;
      background-color: #5147FF;
    }

    .waveform-bar {
      width: 6rpx;
      background-color: rgba(255, 255, 255, 0.8);
      border-radius: 3rpx;
    }
  }
</style>